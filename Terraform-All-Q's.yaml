## 🛠️ What is IaC (Infrastructure as Code)

Infrastructure as Code (IaC) is managing and provisioning infrastructure through machine-readable configuration files.

---

## 🌍 What is Terraform

- Terraform is an Infrastructure as Code tool that lets you build, change, and version infrastructure safely and effectively.
- Infrastructure automation tool.
- Open source by HashiCorp, written in Go.
- Allows infrastructure creation with code.
- Offers CLI tool and Terraform Cloud to store modules privately.

---

## ✅ Advantages of Terraform

- Write, deploy, and destroy infrastructure as code.
- Version Control.
- Consistent environments (Dev, QA, Prod, UAT, Pre-Prod).
- Supports CRUD operations.
- Inventory Management.
- Cost Optimization.
- Dependency Management.
- DRY Principle with Modules.
- Declarative scripting approach.

---

## 📦 Variables and Outputs

### 🔹 Variables
- Serve as parameters for Terraform modules.
- Allow customization without editing source code.

### 🔹 Outputs
- Return values from a module.

### 🔹 Local Values
- Used to assign short names to complex or repeated expressions.

---

## 📁 Terragrunt

- A thin wrapper for Terraform.
- Adds support for managing multiple modules, remote state, and locking.

---

## 🔤 Expressions

### 🔸 Version Constraints
- Example: `version = ">=1.2.0, <2.0.0"`
- Operators: `=`, `!=`, `>`, `<`, `>=`, `<=`

### 🔸 Dynamic Blocks
- Used for nested block creation dynamically.

---

## 🧮 Functions

- `file()` – Read content from a local file.
- `split()` – Split strings based on delimiter.
- `element(list, index)` – Get single element from list.
- `slice(list, start, end)` – Select part of a list.
- `length()` – Get size of a list.
- `lookup(map, key)` – Fetch value for a key in a map.
- `urlencode(string)` – Apply URL encoding.
- `merge()` – Merge variables/maps.
- `min()`, `max()` – Get min/max value.
- `base64encode()`, `base64decode()`
- `concat()` – Combine multiple lists.
- `contains(list, value)` – Check for value existence.

---

## 🧾 HashiCorp Configuration Language (HCL)

- **Variable Types**: `string`, `bool`, `number`, `map`, `list`
- Loops
- Locals
- Data Types
- Functions
- Modules
- Expressions

---

## ❓ Why Terraform

- Works on the principle of API as code.
- Interacts with low-level APIs.
- Supports multiple cloud providers (hybrid cloud).
- Written in Go.
- Uses HCL or JSON format.

---

## ⚙️ Essential Aspects of Terraform

- Console to validate functions.
- Interpolation support.
- `module count` tracks the number of provisioned resources.

---

## 🧩 Terraform Modules

- Logical grouping of Terraform resources.
- Supports multi-env and multi-team use.
- Commonly reused components defined once.

---

## 📂 Terraform State File

- Tracks managed resources.
- Maintains a record of created resources.

---

## 🪟 What is Terraform D

- A Windows plugin used by Terraform.
- `terraform init` looks for it in the plugin directory.

---

## 🔄 Null Resource

- Executes local scripts (e.g., using `local-exec`).
- Doesn’t create actual infrastructure but is useful for provisioning steps.

---

## 🧑‍💻 Most Common CLI Commands

- `terraform init`
- `terraform plan`
- `terraform apply`
- `terraform destroy`
- `terraform destroy --target="resource_name"`
- `terraform refresh`
- `terraform output`
- `terraform graph`

---

## 🗂️ Terraform Backend

- Backend is where the state file is stored.
- Commonly stored in cloud for team collaboration and locking.

---

## 🛰️ Terraform Remote Backend

- Stores state file in a shared cloud location.
- Enables state file locking to avoid conflicts during deployments.

---

## 🔐 Handling Secrets in Terraform

- Environment Variables.
- HashiCorp Vault.
- AWS SSM Parameter Store.
- Use `sensitive = true`.
- Secure remote backends + strict IAM policies.

---

## 🔗 Terraform Resource Graph

- A dependency graph that shows resource relationships.

---

## 🔒 Terraform State Locking

- Prevents concurrent modifications.
- Commonly implemented with DynamoDB.

---

## ❗ Taint Terraform Resource

- Marks a resource as needing replacement.
- Will be recreated during next apply.

## 🔁 Terraform State Rollback

- Used to revert to a previous known state.
- Helpful during failures or misconfigurations in deployments.

---

## ⬆️ How to Upgrade Plugins in Terraform

```bash
terraform init -upgrade
```

- Downloads and upgrades modules/plugins to the newest acceptable version.

---

## 🔗 Sharing Outputs Between Modules

1. **Module 1 (Providing Outputs)**:  
   - Creates resources and defines outputs using `output` blocks.
2. **Module 2 (Consuming Outputs)**:  
   - Uses `module.module1_name.output_name` to consume the output and create dependent resources.

---

## 🏗️ Terraform Architecture Components

- **Sub-Graphs**
- **Evaluation of Expressions**
- **Evaluation of Vertex**
- **Walk the Graph** (builds dependency graph and executes in order)

---

## 📉 What is a Resource Graph

- Visual representation of Terraform-managed infrastructure.
- Helps manage dependencies and parallelism in resource creation.

---

## 🔐 Sentinel Policies Use Cases

- Enforce resource ownership.
- Restrict provider roles.
- Audit Terraform Cloud operations.
- Control usage of certain services or data sources.

### 🎚️ Degrees of Sentinel Policing

1. Advisory  
2. Soft Mandatory  
3. Hard Mandatory

---

## 📁 What is Terragrunt (Recap)

- Thin wrapper for Terraform.
- Simplifies managing multiple modules and remote state.
- Implements DRY principle.

### Use Cases:

1. Managing multiple AWS accounts.
2. Managing infrastructure in different modules.
3. DRY and reusable configurations.

---

## 🔒 State File Locking

- Prevents simultaneous modifications to the same state file.
- Usually implemented via remote backend with state locking (e.g., DynamoDB in AWS).

---

## 🚀 How to Deploy Infra with Terraform

1. Write configuration (`.tf` files).
2. Initialize: `terraform init`
3. Validate: `terraform validate`
4. Plan: `terraform plan`
5. Apply: `terraform apply`

---

## ⚠️ Problems with Terraform

- No native API—relies on provider APIs.
- State File Challenges:
  - Can become monolithic.
  - Requires locking.
  - Cannot update only a part of infra directly.

---

## 🌱 Passing Environment Variables in Terraform

```bash
export TF_VAR_example_var="custom_value"
```

---

## 🔐 Sensitive Variable Output

- Variables marked with `sensitive = true` will not show in CLI output (e.g., `terraform apply`).

---

## 📋 List Created Resources

```bash
terraform state list
```

---

## 🔢 Count Resources Example

```hcl
output "number_of_resources" {
  value = length(aws_instance.example)
}
```

---

## 🧱 Null Resources in Terraform

### What is a Null Resource?

- A resource that performs an action but doesn't create infrastructure.

### Use Cases:

1. Execute local scripts using `local-exec`.
2. Call external APIs.
3. Run custom logic during apply lifecycle.

---

## ✅ Terraform Validate Command

- Checks for syntax and internal consistency.

```bash
terraform validate
```

---

## 🔄 Create Resources Using Loops

### Method 1: Using `count`

```hcl
count = 2
var.name[count.index]
```

### Method 2: Using `for_each`

```hcl
variable "sub" {
  type = set(string)
  default = ["10.1.0.0/24", "10.2.0.0/24"]
}

resource "aws_subnet" "example" {
  for_each = var.sub
  cidr_block = each.value
}
```

---

## ❓ Create Resources Conditionally

```count = var.env == "dev" ? 1 : 0```

---

## 📡 What are Data Sources?

Allow Terraform to fetch and reference existing data/infrastructure.

### Example: AWS AMI

```
data "aws_ami" "latest_amazon_linux" {
  most_recent = true
  owners = ["amazon"]
  filter {
    name   = "name"
    values = ["amzn2-ami-hvm-*-x86_64-gp2"]
  }
}
```

### Example: Vault Secrets

```hcl
data "vault_generic_secrets" "database" {
  path = "secret/data/database"
}

resource "aws_db_instance" "example" {
  username = data.vault_generic_secrets.database.data["username"]
  password = data.vault_generic_secrets.database.data["password"]
}
```

---

## 🔐 Sensitive Variable Example

```hcl
variable "example_password" {
  type        = string
  description = "A Sensitive Variable"
  sensitive   = true
}
```

What are local Variable: These are type of Variable where we cannot

How to Delete particular resources in terraform:
1: terraform destroy -target=resource.name

What resources can be Set variables in with VPC,AutoScaling, LoadBalancer:
AWS VPC : CIDR as Variable
AutoScaling: desired_capacity as Variable
LoadBalancer: LoadBalancer name as variable

How to provide variable at cli:
When declaring variables at tf vars don't pass any default value then it will ask user to enter

Terraform Modules:
Used for Bigger project for consistency
module_name/
  ├── main.tf
  ├── variables.tf
  ├── outputs.tf
  └── README.md (optional)

1: Reusability
2: Abstraction
3: Maintainability
4: Versioning
5: Collaboration

Organization Standards to use terraform:

1: Directory Structure : Root Directory
/my_terraform_project
  ├── main.tf
  ├── variables.tf
  ├── outputs.tf # Shows Values required in terminal
  ├── terraform.tfvars #Variable values for each environment.
  ├── provider.tf
  ├── modules/
  ├── environments/
  └── README.md
2: Use of Modules
3: Variables, inputs, Locals
4: Outputs and Documentation
5: State Management remote backend
6: Naming Conventions : projectname_resource
7: Providers and Authentication
8: Code Review and Collaboration
9: Continuous integration and Continuous Deployment
10: Security Considerations
11: Logging and Monitoring

VPC ,EC2,Cloud Trail,IAM
1: IAM Will Create
2: VPC
3: EC2
4: Cloud Trail

Import Command:

import {
  to = aws_iot_thing.bar
  id = "foo"
}
terraform plan -generate-config-out=generated.tf

Drawbacks of terraform:
1: Error Handling
2: Json and HCL

Terraform Version: 1.5
Hashicorp AWS Version: 5.8.0

Now Terraform Version: 1.7 or 1.8
Now HashiCorp Version: 5.34.0

# How to Manage Secrets in Terraform:

1: Use sensitive keyword in variables section
2: Use AWS SSM Parameters --> Data sources
3: Use Hashi-Corp Vault --> using data sources
4: Environment Variables --> /tmp/password.txt
5: Pass Variables in .tfvars

Using Data Sources We Can leverage the automation for Secrets Management

1: Using Variables files

variable "database_password" {
  type        = string
  sensitive   = true
  description = "Password for the database"
}
2: AWS Systems Manager Parameters Store or Secrets Manager:

retrieve sensitive information such as passwords, API keys, or other credentials

data "aws_ssm_parameter" "database_password" {
  name = "/myapp/database_password"
}

resource "aws_instance" "example" {
  ami           = "ami-12345678"
  instance_type = "t2.micro"

  user_data = <<-EOF
              #!/bin/bash
              echo "Database Password: ${data.aws_ssm_parameter.database_password.value}" > /tmp/password.txt
              EOF
}

3: External Secrets Management: Hashi-Corp Vault

provider "vault" {
  address = "https://vault.example.com:8200"
  token   = "your_vault_token"
}

data "vault_generic_secret" "database_credentials" {
  path = "secret/myapp/database"
}

resource "aws_instance" "example" {
  ami           = "ami-12345678"
  instance_type = "t2.micro"

  user_data = <<-EOF
              #!/bin/bash
              echo "Database Username: ${data.vault_generic_secret.database_credentials.data["username"]}" > /tmp/username.txt
              echo "Database Password: ${data.vault_generic_secret.database_credentials.data["password"]}" > /tmp/password.txt
              EOF
}

4: Using Environment Variables:

variable "database_password" {
  type = string
}

resource "aws_instance" "example" {
  ami           = "ami-12345678"
  instance_type = "t2.micro"

  user_data = <<-EOF
              #!/bin/bash
              echo "Database Password: $DATABASE_PASSWORD" > /tmp/password.txt
              EOF
}

You have a Parent Module and Child Module :
Using terraform workspaces
Terraform is platform agnostic
1: terraform workspace new dev
2: terraform workspace select dev
3: Modules
4: terraform apply -var-file=dev.tfvars

Scenarios:
End To End Terraform Flow
1: First Write Tf files
2: Terraform init
3: Terraform validate
4: Terraform plan
5: Terraform fmt --> Write Canonical Form mostly used in Import

One Particular Resource needs to be recreated :
1: Using terraform taint we can create a particular resource in next apply command

Terraform tain is command used to represent that particular resource is degraded or upgraded or damaged need to be replaced in next apply

1: Terraform state list
2: terraform taint "resources_name"
3: terraform apply

terraform taint and untaint

terraform taint is deprecated instead we use

terraform apply --replace=<resource-name>

# One Particular resource needs to be deleted:

terraform destroy -target=aws_instance.my_instance

# Explain the various types of meta-arguments:

Meta arguments:
changes the default behaviors of terraform configuration

1: depends_on[list of resources]
2: count
3: for_each
4: provider

provider "aws" {
  alias  = "europe"
  region = "europe-west1"
}
resource "aws" "name" {
  provider = aws.europe
}

5: lifecycle -- > create_before_destroy
lifecycle {
    create_before_destroy = true
    ignore_changes = [tags["Name"],]
    prevent_destroy =
    replace_triggered_by = [aws_ecs_service.svc.id]
  }

# Who Created terraform.tfstate.backup file
terraform destroy command will create the backup file
it is because that to restore the infra to the same state

# Force Unlock --> Manually delete lock on terraform file
terraform apply --force-unlock

# Terraform Refresh
1: When ever there is a mismatch in terraform statefile we run this command

# Interview Session - 1:

Components used in creating the terraform:
1: VPC
2: Subnets
3: s3
4: IAM
5: Kubernetes
6: VMs

How to do changes in the already created configuration :

Using " Terraform import " command we can do changes which are already created.

State file is get and stored:
Locally or Remote Backend

If we loose state file:  There is no way to get back so we need to lock and save it in Storage

Terraform Validate: used to validate the syntax
Terraform fmt

Types of Modules in terraform:

1: Root Module: Main Module to be called with all configurations
2: Child Module: called with in the root module and get created based on the structure
3: Module Sources: Modules can be sourced from various locations.

Remote Backend: Used for Locking and storing

How to pass variable over run time:
variable.tf
variable "aws" {
  type = string
}

How to Manage Modules in Multiple Environments:
using terraform workspace

Traditional IT Infra:
1: Slow Deployment
2: Expensive
3: Limited Automation
4: Human Error
5: Wasted Resources
6: Inconsistency

Terraform Providers:
Terraform Provider is a Plugin that lets terraform managers an external api
when we run terraform init plugin required for the provider are automatically downloaded and saved locally

Resource Block :
Describe one or more infrastructure objects

Hashi-Corp Maintained: No need Required Providers section

Non Hashi-Corp Maintained: Need to provide required_providers Section

terraform {
  required_providers {
    aws = {
      source = "hashicorp/aws"
      version = "5.22.12"
    }
  }
}

provider "aws" {
  region = "us-east-1"
}

resource "aws_instance" "resource_name" {
  ami = "ami_id"
  instance_type="t2.micro"
}

How to debug and troubleshoot the terraform:
1: terraform init and terraform debug
2: terraform init
3: terraform validate
4: terraform fmt
5: terraform plan -debug (enable debug output gives detailed info about the terraform doing)
6: terraform state (terraform show)
7: increase verbosity using trace command
TF_LOG=TRACE terraform plan
8: to check the function issues we use terraform console
9: terraform init -upgrade

Terraform fmt:
document some commonly accepted formatting guidelines for terraform code these conventions can e enforced automatically with terraform fmt

Configuration Syntax in terraform:
1: Arguments key value pairs
2: Blocks are used to mention resources
3: identifiers = terraform specific constructs like resources,input variables,etc .. are all identifiers
4: Comments

Terraform Cloud:
1: Manages StateFiles in Terraform Cloud
2: Store Variables
Write some Code for Providers:
terraform {
  required_providers {
    aws = {
      source = "hashicorp/aws"
      version = "5.22.0"
    }
  }
}
provider "aws" {
  alias = "us-east"
  region = "us-east-1"
}

resource "aws_instance" "Jenkins" {
  ami = "ami_id"
  instance_type = "t2.micro"
  security_groups =
  key_pair =
}

Locals: # Locals
locals {
  environment_name = "production"
}
Data-Sources: # Data Sources
data "aws_ami" "latest_amazon_linux" {
  most_recent = true
  owners      = ["amazon"]

  filter {
    name   = "name"
    values = ["amzn2-ami-hvm-*-x86_64-gp2"]
  }
}
variables: # Variables
variable "region" {
  type    = string
  default = "us-west-2"
}

variable "instance_types" {
  type    = list(string)
  default = ["t2.micro", "t2.small", "t2.medium"]
}
life-cycle: # Resources
resource "aws_instance" "ec2_instances" {
  count         = length(var.instance_types)
  instance_type = var.instance_types[count.index]
  ami           = data.aws_ami.latest_amazon_linux.id
  tags          = local.tags

# Life Cycle
  lifecycle {
    create_before_destroy = true
    prevent_destroy       = false
  }
}
for:
# For Loop Example
resource "aws_s3_bucket" "example_buckets" {
  count         = 3
  bucket        = "example-bucket-${count.index}"
  acl           = "private"
  force_destroy = true
}

for-each:
# For Each Loop Example
variable "vpc_cidrs" {
  type    = map(string)
  default = {
    "us-west-1" = "10.0.0.0/16"
    "us-east-1" = "10.1.0.0/16"
    "eu-west-1" = "10.2.0.0/16"
  }
}
resource "aws_vpc" "vpcs" {
  for_each = var.vpc_cidrs

  cidr_block = each.value
  tags       = {
    Name = "VPC-${each.key}"
  }
}
dynamic block: # Dynamic Block Example

variable "additional_tags" {
  type = map(string)
  default = {
    app = "web"
    env = "prod"
  }
}

# resource "aws_instance" "dynamic_tags" {
#   count = 2
#   ami   = data.aws_ami.latest_amazon_linux.id
#   tags = merge(
#     local.tags,
#     {
#       Name = "instance-${count.index + 1}"
#     },
#     var.additional_tags
#   )
#   }

Condition :

# Condition Example
resource "aws_security_group" "example_sg" {
  name        = "example_sg"
  description = "Example Security Group"

  ingress {
    from_port   = 80
    to_port     = 80
    protocol    = "tcp"
    cidr_blocks = var.region == "us-west-2" ? ["0.0.0.0/0"] : []
  }
}

Resource:

# Data Sources
data "aws_ami" "latest_amazon_linux" {
  most_recent = true
  owners      = ["amazon"]

  filter {
    name   = "name"
    values = ["amzn2-ami-hvm-*-x86_64-gp2"]
  }
}

# Resources LifeCycle

resource "aws_instance" "ec2_instances" {
  count         = length(var.instance_types)
  instance_type = var.instance_types[count.index]
  ami           = data.aws_ami.latest_amazon_linux.id
  tags          = local.tags

  lifecycle {
    create_before_destroy = true
    prevent_destroy       = false
    ignore_changes = ["tags", "metadata"]
    ignore_changes_on_replace = ["volume_size"]
  }
}

Depends on:

1: Reduced Parallelism
2: Hard-Coding Dependencies
3: Increased Complexity

resource "aws_instance" "example" {
  ami           = "ami-12345678"
  instance_type = "t2.micro"
  # other resource configurations
  depends_on = [aws_s3_bucket.example_bucket]
}

resource "aws_s3_bucket" "example_bucket" {
  bucket = "example-bucket"
  acl    = "private"
  # other resource configurations
}


Terraform Provisioners:
1: Local Exec Provisioners: commands will execute locally on the machine where terraform is executed
resource ""

resources "ec2_instances" "example" {
  ami = "ami"
  instance_type = "t2.micro"
  provisioner "local-exec" {
    command = "echo 'provisioned only oif count is even"
    when = var.count%2 == 0
  }
}
2: Remote Exec: Commands will be run at a remote machines
resources "ec2_instances" "example"{
  ami = "ami"
  instance_type = "t2.micro"
provisioner "remote-exec" {
  inline = [
    "sudo apt-get update"
    "sudo apt-get install -y nginx"
  ]
 }
}

3: File Provisioner:
resource "ec2_instance" "example" {
  ami = "ami"
  instance_type = "t2.micro"
  provisioner "file" {
    src = "local/path"
    destination = "remote path"
  }
}

Assertion in Terraform:
variables {
  bucket_prefix = "test"
}
run "valid_string_concat" {
  command = plan
  assert {
    condition = aws_s3_bucket.bucket.bucket == "test-bucket"
    error_message = "S3 bucket"
  }
}

Different Types of Build in Functions:
1: String Functions
2: Numeric Functions
3: Collection Functions
4: Encoding Functions
5: File System Functions
6: Data and Time Functions
7: Hash and Crypto Functions
8: Ip Network Functions
9: Type Conversion Functions

Diff Between For_each and Dynamic block:
both are used to create a multiple instance of a nested block
for_each will work with all kind of data types
list,sets,maps,objects
Dynamic Block will work for list and sets
for each is easy when compared to Dynamic Block

provider "aws" {
  region = "us-east-1"
}

resources "ec_instance" "first" {
  ami = "ami"
  instance_type = "t2.micro"

  dynamic "setting" {
    for_each = var.sq_ingress_rules
    content {
      namespace = setting.value['description']
      name = setting.value['name']
      value = setting.value['value']
    }
  }
}

locals {
  coordinates = (10,20,30)
  y_coordinates = element(local.coordinates,1)
}

---

What are private Modules:
1: we declare the configuration files in the one repository push it in the github
2: in another folder we calll them to create a resources with the provider block

Types of Modules:
1: Root module
2: Child Module
3: Published Modules
4: Using Modules
5: Developing Modules

Folder Structure or Module:
1: Licence
2: ReadMe.md
3: main.tf
4: variables.tf
5: outputs.tf

Naming Convention for Terraform Cloud:
1: terraform-provider-cloud

Terraform State Commands:
1: terraform state list
2: terraform state pull
3: terraform state push
4: terraform state refresh
5: terraform state replace-provider old-provider new-provider


### Terraform Backend Configuration
- terraform {
  required_version: v12
  required_providers: {
    aws {
          version: v13
          soruce: "hashicorp/aws""
    }  
  }
  backend: "S3" {
  bucket = 
  key: =
  region = 
  profile = 
  }

}
provider "aws" {

region= sws
}

terraform {
backend "azurerm"{
use_msi = true
use_azureAuth_id = true
tenant_id = "sdfhnsjhndf"
client_id = "ssdjskdjs"
storage_accountname = "zdjsdhsjd"
container_name = tfstate
key = "prod,tfstate.files"
}
}

Output ip to ansible text file 

terraform output -json vm_ips | jq -r '.[]' > hosts.txt

outputs "vm_ips" {
value = "aws_instance_id.id"
}



